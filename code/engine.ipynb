{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imports import *\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using tensorflow's CNN and opencv to classify images\n",
    "Steps of implimenting it as follows :\n",
    "Load the data from disk or get the live feed from the camera\n",
    "Find the face in the image\n",
    "Crop the face from the image\n",
    "Resize the image and feed it to the CNN\n",
    "Get the output from the CNN\n",
    "Match the output with the labels and display the name of the person\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a function which will be used to create a model for image classification which loads the data, trains the model and then predicts the output\n",
    "# the class will be used to create a model for image classification\n",
    "\n",
    "class ImageClassifier:\n",
    "    # path can be either path to folder or inbuilt dataset\n",
    "    def __init__(self, path=None):\n",
    "        self.path = path\n",
    "        self.data = self.imagegathering()\n",
    "        self.model = self.createmodel()\n",
    "        self.model.fit(self.data)\n",
    "        self.model.predict(self.data)\n",
    "        \n",
    "    \n",
    "    def imagegathering(self):\n",
    "        if self.path is not None:\n",
    "            data = []\n",
    "            for i in os.listdir(self.path):\n",
    "                data.append(i)\n",
    "            return data\n",
    "        else:\n",
    "            lfw_people = fetch_lfw_people(min_faces_per_person=100, resize=0.4)\n",
    "            faces = lfw_people.data\n",
    "            labels = lfw_people.target\n",
    "            print(faces.shape)\n",
    "            return faces\n",
    "\n",
    "\n",
    "\n",
    "    # creating a function which will be used to create a model for image classification\n",
    "    def createmodel(self):\n",
    "        model = tf.keras.models.Sequential()\n",
    "        base_model = tf.keras.applications.EfficientNetB2(include_top=False, weights='imagenet', input_shape=(64, 64, 3), trainable=False)\n",
    "        model.add(base_model)\n",
    "        model.add(tf.keras.layers.GlobalAveragePooling2D())\n",
    "        model.add(tf.keras.layers.Dense(1024, activation='relu'))\n",
    "        model.add(tf.keras.layers.Dense(512, activation='relu'))\n",
    "        model.add(tf.keras.layers.Dense(len(np.unique(self.labels)), activation='softmax'))\n",
    "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "\n",
    "# creating an object of the class ImageClassifier\n",
    "imageclassifier = ImageClassifier(path = None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = fetch_lfw_people(min_faces_per_person=10, resize=0.4)\n",
    "\n",
    "# resize the images to 64x64\n",
    "images.images = np.array([cv2.resize(image, (1000, 1000)) for image in images.images])\n",
    "\n",
    "# plot 50 random images from the dataset\n",
    "fig, ax = plt.subplots(3, 10)\n",
    "for i, axi in enumerate(ax.flat):\n",
    "    axi.imshow(images.images[i])\n",
    "    fig.set_size_inches(25, 10)\n",
    "    axi.set(xticks=[], yticks=[],\n",
    "            xlabel=images.target_names[images.target[i]])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "985f7a9bca016dcd54de021bb7defc981ed615f3c64c65433f0687ce1ea85fc5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
